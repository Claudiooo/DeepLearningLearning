{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural network tutorial ANN\n",
    "\n",
    "## Getting started with a extremely simple neural network\n",
    "\n",
    "Today, we will have a first sight of what a really simple neural network is and what we can do with it.\n",
    "\n",
    "### Basic working of backpropagation through a simple neural network implementation\n",
    "\n",
    "In this little tutorial, we assume that you have a basic understanding of how python language works, and also knowledge about the numpy library (you can have a look about it here : [tutorial numpy](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html) ).\n",
    "We will see in this tutorial several notions, as matrix, layers, input/output dataset, node etc.\n",
    "\n",
    "Now, let's get started with our first little neural network which will train with backpropagation, trying to use the input in order to predict the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nonlinearity mapping the sigmoid function.\n",
    "The sigmoid function maps values to values between 0 and 1 => useful for probatilities after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of our input dataset as a numpy matrix.\n",
    "1 row = one training example ;\n",
    "1 column = one input nodes ;\n",
    "([4,3] matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output dataset\n",
    "\n",
    "(After the transposition, it's represented as [4,1] matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding random numbers\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our weight matrix.\n",
    "We need a matrix of weights to link our two layers input and output.\n",
    "It is a [3,1] matrix since we have 3 inputs and one single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn0 = 2*np.random.random((3,1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop iteration of the training network, in order to optimize it to the dataset.\n",
    "\n",
    "* lay0 => data (X contains 4 training examples that we will process all together at the same time : it is called a full batch training).\n",
    "\n",
    "* lay1 => we let the network trying to predict the output, then we will study it and readapt at each iteration\n",
    "\n",
    "* np.dot(lay0,syn0) => multiply lay0 by syn0, then pass the output through the sigmoid function ( nonlin() ).\n",
    "\n",
    "* lay1_error => after the lay1's potential predict output, we can compare his efficiency by substracting the correct output y by the prediction lay1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(10000):\n",
    "\n",
    "    lay0 = X\n",
    "    lay1 = nonlin(np.dot(lay0,syn0))\n",
    "\n",
    "    lay1_error = y - l1\n",
    "\n",
    "    lay1_delta = lay1_error * nonlin(lay1,True)\n",
    "\n",
    "    syn0 += np.dot(lay0.T,lay1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results After Training:\n",
      "[[ 0.00639642]\n",
      " [ 0.00521038]\n",
      " [ 0.99574974]\n",
      " [ 0.9947811 ]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Results After Training:\")\n",
    "print (lay1) #the more it is near to 1, the more accurate it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can afterward change your dataset, to do some test of accuracy, imagine some new matrix patterns with new correlation between input column for exemple, to train your neural network (but don't forget to adapt the code aswell !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
