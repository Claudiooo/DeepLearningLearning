{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep leaning tutoriel\n",
    "## Definitions\n",
    "\n",
    "**Machine learning** is about defining the outcome and letting your algorithm learn the step to get here.\n",
    "\n",
    "There is tree differents learning styles :\n",
    " * Supervised\n",
    " * Unsupervised\n",
    " * Reinforcement\n",
    "\n",
    "**Deep Learning** is a subcategory of machine learning, it derives more precisely of neural network. The deeplearning consists to combine succesive layers of neural network.\n",
    " \n",
    "**Linear Regression** models relationship between independent and dependant variables via line of best fit.\n",
    "\n",
    "## Linear Regression using Gradient Descent algorithm\n",
    "\n",
    "### GISS Surface Temperature Analysis from NASA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as FF\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~nicolasconstanty/0 or inside your plot.ly account where it is named 'sample-data-table'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~nicolasconstanty/0.embed\" height=\"230px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('GLB.Ts+dSST.csv')\n",
    "\n",
    "sample_data_table = FF.create_table(df.head())\n",
    "py.iplot(sample_data_table, filename='sample-data-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~nicolasconstanty/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "for month in df:\n",
    "    if (month != 'Year'):\n",
    "        traces.append(go.Scatter(\n",
    "                      x = df['Year'], y = df[month],\n",
    "                      name= month\n",
    "                      ))\n",
    "layout = go.Layout(\n",
    "                  title='Global-mean monthly, seasonal, and annual means (1880-present)',\n",
    "                  plot_bgcolor='rgb(230, 230,230)', \n",
    "                  showlegend=True\n",
    "                  )\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='GLB.Ts+dSST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These curves represent the temperature anomalies from 1880 to present, i.e. deviations from the corresponding 1951-1980 means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression error (formula)\n",
    "\n",
    "![linear_regression_error](https://raw.githubusercontent.com/Claudiooo/DeepLearningLearning/Group2/Images/linear_regression_error1.png)\n",
    "\n",
    "### Linear regression error (Implementation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LinearRegressionError(b, m, values):\n",
    "    error = 0\n",
    "    for val in values:\n",
    "        error += (val[1] - (m * val[0] + b)) ** 2\n",
    "    return error / float(len(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression gradient (formula)\n",
    "\n",
    "![linear_regression_gradient](https://raw.githubusercontent.com/Claudiooo/DeepLearningLearning/Group2/Images/linear_regression_gradient1.png)\n",
    "\n",
    "### Linear regression gradient (Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(current_b, current_m, values, learing_rate):\n",
    "    gradient_b = 0\n",
    "    gradient_m = 0\n",
    "    n = len(values)\n",
    "    for val in values:\n",
    "        gradient_m += -(2 / n) * val[0] * (val[1] - (current_m * val[0] + current_b))\n",
    "        gradient_b += -(2 / n) * (val[1] - (current_m * val[0] + current_b))\n",
    "    new_b = current_b - (learing_rate * gradient_b)\n",
    "    new_m = current_m - (learing_rate * gradient_m)\n",
    "    return [new_b, new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = -20, m = -20, error = 167932.21884420287\n",
      "After 8000 iterations b = -18.923944094830862, m = 0.9717245498225097, error = 0.050930232301069085\n"
     ]
    }
   ],
   "source": [
    "#iniatial_b = 0\n",
    "#iniatial_m = 0\n",
    "#number_iteration = 4000\n",
    "#learning_rate = 0.0001\n",
    "\n",
    "B = 0\n",
    "M = 0\n",
    "\n",
    "def run(initial_b, initial_m, number_iteration, learning_rate):\n",
    "    b = initial_b\n",
    "    m = initial_m\n",
    "    values = []\n",
    "    for i in range(len(df['Year'])):\n",
    "        values.append([df['Year'][i] * 0.01, df['Jan'][i]])\n",
    "    print(\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, LinearRegressionError(initial_b, initial_m, values)))\n",
    "    for i in range(number_iteration):\n",
    "        [b, m] = step_gradient(b, m, values, learning_rate)\n",
    "    print(\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(number_iteration, b, m, LinearRegressionError(b, m, values)))\n",
    "    global B\n",
    "    global M\n",
    "    B = b\n",
    "    M = m\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run(-20, -20, 8000, 0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~nicolasconstanty/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "    x = df['Year'], y = df['Jan'],\n",
    "    name= 'Jan',\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='rgba(255, 165, 196, 0.95)',\n",
    "        line=dict(\n",
    "            color='rgba(156, 165, 196, 1.0)',\n",
    "            width=1,\n",
    "        ),\n",
    "            symbol='circle',\n",
    "            size=10,\n",
    "        )\n",
    "    )\n",
    "xTab = [1880, 2017]\n",
    "yTab = [(M * xTab[0] * 0.01 + B), (M * xTab[1] * 0.01 + B)]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = xTab,\n",
    "    y = yTab,\n",
    "    name = 'Best fit'\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title='January anomaly from 1880 to present',\n",
    "    plot_bgcolor='rgb(230, 230,230)',\n",
    "    showlegend=True\n",
    ")\n",
    "fig = go.Figure(data=[trace, trace1], layout=layout)\n",
    "py.iplot(fig, filename='dot_Jan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "### Definission\n",
    "The perceptron is an algorithm for supervised learning of binary classifiers. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector.\n",
    "\n",
    "### Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activationFunc(number):\n",
    "    return 1 if number > 0 else -1\n",
    "    \n",
    "class Perceptron:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        for i in range(size):\n",
    "            self.weights.append(random.uniform(-1.0, 1.0))\n",
    "            \n",
    "    def guess(inputs):\n",
    "        sum = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            sum += inputs[i] * weights[i]\n",
    "        return activationFunc(sum)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
